{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T23:37:37.134667Z","iopub.status.busy":"2023-11-13T23:37:37.134405Z","iopub.status.idle":"2023-11-13T23:37:44.542073Z","shell.execute_reply":"2023-11-13T23:37:44.541015Z","shell.execute_reply.started":"2023-11-13T23:37:37.134643Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import torch\n","\n","# Rely on transformation functions in torch\n","import torchvision.transforms as transforms\n","from torchvision.io import read_image\n","import pandas as pd # for data manipulation\n","import torch.nn as nn # nn: neural network module\n","import os\n","import warnings\n","import numpy as np\n","import seaborn as sns # to visualize data\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n","from torchmetrics.classification import MulticlassF1Score\n","\n","# Note: if there is no nvidia gpu, set cuda:0 to cpu\n","warnings.filterwarnings('ignore')\n","DEVICE = 'cuda:0'"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T13:55:09.370542Z","iopub.status.busy":"2023-11-13T13:55:09.370124Z","iopub.status.idle":"2023-11-13T13:55:09.379555Z","shell.execute_reply":"2023-11-13T13:55:09.378544Z","shell.execute_reply.started":"2023-11-13T13:55:09.370516Z"},"trusted":true},"outputs":[],"source":["class CustomImageDataset(Dataset):\n","    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None, filter_fn=None):\n","        \n","        # Read images using pandas\n","        self.img_labels = pd.read_csv(annotations_file, sep=' ', header=None)\n","        if filter_fn is not None:\n","            self.img_labels = self.img_labels[self.img_labels[19] == filter_fn]\n","        \n","        # Save image directory\n","        self.img_dir = img_dir\n","        \n","        # Saving transformation\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    # Return the number of images \n","    def __len__(self):\n","        return len(self.img_labels)\n","    \n","    # Constructs the image path using \n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n","        image = read_image(img_path)\n","        label = self.img_labels.iloc[idx, 2]\n","        if self.transform:\n","            image = self.transform(image)\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","        cat = {'mono': 0, 'poly': 1, np.nan: 3}[self.img_labels.iloc[idx, 19]]\n","        return image, label, cat"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T13:55:09.380866Z","iopub.status.busy":"2023-11-13T13:55:09.380619Z","iopub.status.idle":"2023-11-13T13:55:09.390345Z","shell.execute_reply":"2023-11-13T13:55:09.389611Z","shell.execute_reply.started":"2023-11-13T13:55:09.380842Z"},"trusted":true},"outputs":[],"source":["class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n","        # forced to call the constructor of the parent class to get ResidualBlock\n","        # working as a pytorch module\n","        super(ResidualBlock, self).__init__()\n","        \n","        # Self.conv1 is the main computation\n","        # 3x3 convolution batch normalization and ReLU \n","        self.conv1 = nn.Sequential(\n","                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n","                        nn.BatchNorm2d(out_channels),\n","                        nn.ReLU()) # Using ReLU to fix vanishing gradient problem\n","        \n","        # Also a 3x3 convolution batch but takes in conv1's output to refine conv1's features\n","        self.conv2 = nn.Sequential(\n","                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n","                        nn.BatchNorm2d(out_channels))\n","        \n","        self.downsample = downsample # Optional downsample\n","        self.relu = nn.ReLU()\n","        self.out_channels = out_channels\n","\n","    # Transform input data into output predictions     \n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.conv2(out)\n","        if self.downsample:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","        return out"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T13:55:09.392973Z","iopub.status.busy":"2023-11-13T13:55:09.392650Z","iopub.status.idle":"2023-11-13T13:55:09.407293Z","shell.execute_reply":"2023-11-13T13:55:09.406542Z","shell.execute_reply.started":"2023-11-13T13:55:09.392943Z"},"trusted":true},"outputs":[],"source":["class ResNet(nn.Module):\n","    def __init__(self, block, layers):\n","        super(ResNet, self).__init__()\n","        self.inplanes = 64\n","        self.conv1 = nn.Sequential(\n","                        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3),\n","                        nn.BatchNorm2d(64),\n","                        nn.ReLU())\n","        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n","\n","        # Constructed 4 residual layers\n","        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n","        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n","        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n","        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n","        self.avgpool = nn.AvgPool2d(7, stride=1)\n","        self.fc = nn.Linear(512, 4)\n","        \n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes:\n","            \n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n","                nn.BatchNorm2d(planes),\n","            )\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","    \n","    \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.maxpool(x)\n","        x = self.layer0(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        m_x = torch.softmax(self.fc(x), dim=-1)\n","\n","        return m_x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T13:55:09.408483Z","iopub.status.busy":"2023-11-13T13:55:09.408236Z","iopub.status.idle":"2023-11-13T13:55:12.502716Z","shell.execute_reply":"2023-11-13T13:55:12.501533Z","shell.execute_reply.started":"2023-11-13T13:55:09.408461Z"},"trusted":true},"outputs":[],"source":["dataset = CustomImageDataset('/kaggle/input/elpv-dataset-master/labels.csv', '/kaggle/input/elpv-dataset-master/images', transform=transforms.Compose([\n","                transforms.ToPILImage(), \n","                transforms.Grayscale(num_output_channels=3),\n","                transforms.Resize((224, 224)),\n","                transforms.ToTensor()\n","            ]),\n","                            target_transform=lambda x: int(x * 3))\n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(len(dataset) * 0.75), int(len(dataset) * 0.25)])\n","train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n","\n","# Create an instance of the resNet model which is moved to DEVICE (idk how to get this working for AMD)\n","model = ResNet(ResidualBlock, [3, 4, 3, 4]).to(DEVICE)\n","\n","# Learning rate (common starting point, too high and the model might fail coverage)\n","lr = 0.001\n","# Set to 100 passes through entire dataset\n","epochs = 100\n","\n","loss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay = 0.001, momentum=0.9) "]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T13:55:12.504800Z","iopub.status.busy":"2023-11-13T13:55:12.504107Z","iopub.status.idle":"2023-11-13T13:55:12.517984Z","shell.execute_reply":"2023-11-13T13:55:12.517021Z","shell.execute_reply.started":"2023-11-13T13:55:12.504771Z"},"trusted":true},"outputs":[],"source":["def process(model, loss_fn, optimizer, epochs, train_dataloader, test_datalodaer):\n","    for epoch in range(epochs):\n","        metric = MulticlassF1Score(num_classes=4, average='macro').to('cuda:0')\n","        steps = 0\n","        acc_loss = 0.0\n","        for image, label, cat in train_dataloader:\n","            image = image.to('cuda:0')\n","            label = label.to('cuda:0')\n","            optimizer.zero_grad()\n","            outputs = model(image)\n","            loss = loss_fn(outputs, label)\n","            loss.backward()\n","            optimizer.step()\n","            steps += 1\n","            acc_loss += loss.item()\n","        print(f'Epoch: {epoch} | Train Loss: {acc_loss / steps}')\n","        \n","        with torch.no_grad():\n","            steps = 0\n","            acc_loss = 0.0\n","            for image, label, cat in test_dataloader:\n","                image = image.to('cuda:0')\n","                label = label.to('cuda:0')\n","                outputs = model(image)\n","                loss = loss_fn(outputs, label)\n","                steps += 1\n","                acc_loss += loss.item()\n","                metric.update(torch.argmax(outputs, dim=-1), label)\n","            print(f'Epoch: {epoch} | Test Loss: {acc_loss / steps} | Test F1: {metric.compute()}')\n","\n","        "]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T13:55:12.521350Z","iopub.status.busy":"2023-11-13T13:55:12.520718Z","iopub.status.idle":"2023-11-13T14:22:38.820975Z","shell.execute_reply":"2023-11-13T14:22:38.820067Z","shell.execute_reply.started":"2023-11-13T13:55:12.521315Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0 | Train Loss: 1.2607151418924332\n","Epoch: 0 | Test Loss: 1.1511670748392742 | Test F1: 0.22577610611915588\n","Epoch: 1 | Train Loss: 1.110164724290371\n","Epoch: 1 | Test Loss: 1.1081768075625102 | Test F1: 0.31094592809677124\n","Epoch: 2 | Train Loss: 1.0787195712327957\n","Epoch: 2 | Test Loss: 1.0914395054181416 | Test F1: 0.3334586024284363\n","Epoch: 3 | Train Loss: 1.0681684985756874\n","Epoch: 3 | Test Loss: 1.079145888487498 | Test F1: 0.34498846530914307\n","Epoch: 4 | Train Loss: 1.05283909663558\n","Epoch: 4 | Test Loss: 1.0678186615308125 | Test F1: 0.35438072681427\n","Epoch: 5 | Train Loss: 1.04617602750659\n","Epoch: 5 | Test Loss: 1.0602370301882427 | Test F1: 0.35645750164985657\n","Epoch: 6 | Train Loss: 1.0394245125353336\n","Epoch: 6 | Test Loss: 1.056873857975006 | Test F1: 0.36235252022743225\n","Epoch: 7 | Train Loss: 1.0375838726758957\n","Epoch: 7 | Test Loss: 1.0587756236394246 | Test F1: 0.3534063994884491\n","Epoch: 8 | Train Loss: 1.0264788568019867\n","Epoch: 8 | Test Loss: 1.0374229152997334 | Test F1: 0.37775787711143494\n","Epoch: 9 | Train Loss: 1.0196084193885326\n","Epoch: 9 | Test Loss: 1.0449571410814922 | Test F1: 0.36792895197868347\n","Epoch: 10 | Train Loss: 1.0191020481288433\n","Epoch: 10 | Test Loss: 1.0464378595352173 | Test F1: 0.3681413531303406\n","Epoch: 11 | Train Loss: 1.0088797360658646\n","Epoch: 11 | Test Loss: 1.0347876250743866 | Test F1: 0.3695812225341797\n","Epoch: 12 | Train Loss: 0.9992950893938541\n","Epoch: 12 | Test Loss: 1.0408259232838948 | Test F1: 0.3609931468963623\n","Epoch: 13 | Train Loss: 0.9925198890268803\n","Epoch: 13 | Test Loss: 1.0306327641010284 | Test F1: 0.3742384910583496\n","Epoch: 14 | Train Loss: 0.9828443750739098\n","Epoch: 14 | Test Loss: 1.0348343749841054 | Test F1: 0.36789995431900024\n","Epoch: 15 | Train Loss: 0.9794480577111244\n","Epoch: 15 | Test Loss: 1.030239423116048 | Test F1: 0.3682558536529541\n","Epoch: 16 | Train Loss: 0.9723189435899258\n","Epoch: 16 | Test Loss: 1.045108864704768 | Test F1: 0.36267340183258057\n","Epoch: 17 | Train Loss: 0.9673607386648655\n","Epoch: 17 | Test Loss: 1.032689740260442 | Test F1: 0.36563944816589355\n","Epoch: 18 | Train Loss: 0.9628841243684292\n","Epoch: 18 | Test Loss: 1.0411865711212158 | Test F1: 0.3644692301750183\n","Epoch: 19 | Train Loss: 0.9645095132291317\n","Epoch: 19 | Test Loss: 1.040047566095988 | Test F1: 0.36582690477371216\n","Epoch: 20 | Train Loss: 0.9554505869746208\n","Epoch: 20 | Test Loss: 1.0372869769732158 | Test F1: 0.3643176555633545\n","Epoch: 21 | Train Loss: 0.9512374736368656\n","Epoch: 21 | Test Loss: 1.0268236498037975 | Test F1: 0.3708634376525879\n","Epoch: 22 | Train Loss: 0.9492180608212948\n","Epoch: 22 | Test Loss: 1.0350500643253326 | Test F1: 0.36088746786117554\n","Epoch: 23 | Train Loss: 0.9480823464691639\n","Epoch: 23 | Test Loss: 1.042466362317403 | Test F1: 0.36067092418670654\n","Epoch: 24 | Train Loss: 0.9470738843083382\n","Epoch: 24 | Test Loss: 1.0361888706684113 | Test F1: 0.36506813764572144\n","Epoch: 25 | Train Loss: 0.9455588944256306\n","Epoch: 25 | Test Loss: 1.061619222164154 | Test F1: 0.3613749146461487\n","Epoch: 26 | Train Loss: 0.9497654438018799\n","Epoch: 26 | Test Loss: 1.0475263098875682 | Test F1: 0.3527817130088806\n","Epoch: 27 | Train Loss: 0.9522035233676434\n","Epoch: 27 | Test Loss: 1.0502287149429321 | Test F1: 0.35817834734916687\n","Epoch: 28 | Train Loss: 0.9461611248552799\n","Epoch: 28 | Test Loss: 1.0452383557955425 | Test F1: 0.3617544174194336\n","Epoch: 29 | Train Loss: 0.9496291987597942\n","Epoch: 29 | Test Loss: 1.041473666826884 | Test F1: 0.36762285232543945\n","Epoch: 30 | Train Loss: 0.9425690025091171\n","Epoch: 30 | Test Loss: 1.0479999979337056 | Test F1: 0.36481115221977234\n","Epoch: 31 | Train Loss: 0.9446854069828987\n","Epoch: 31 | Test Loss: 1.0449851353963215 | Test F1: 0.3602837324142456\n","Epoch: 32 | Train Loss: 0.9386417157948017\n","Epoch: 32 | Test Loss: 1.0345422327518463 | Test F1: 0.3638682961463928\n","Epoch: 33 | Train Loss: 0.9319385513663292\n","Epoch: 33 | Test Loss: 1.0332402090231578 | Test F1: 0.3746015727519989\n","Epoch: 34 | Train Loss: 0.9339649267494678\n","Epoch: 34 | Test Loss: 1.0481829643249512 | Test F1: 0.3582279086112976\n","Epoch: 35 | Train Loss: 0.9349182732403278\n","Epoch: 35 | Test Loss: 1.0392295916875203 | Test F1: 0.3619849681854248\n","Epoch: 36 | Train Loss: 0.9322739951312542\n","Epoch: 36 | Test Loss: 1.0415875315666199 | Test F1: 0.3669424057006836\n","Epoch: 37 | Train Loss: 0.9333360716700554\n","Epoch: 37 | Test Loss: 1.0469578504562378 | Test F1: 0.36472374200820923\n","Epoch: 38 | Train Loss: 0.9343049377202988\n","Epoch: 38 | Test Loss: 1.0471491018931072 | Test F1: 0.3574559688568115\n","Epoch: 39 | Train Loss: 0.9495517574250698\n","Epoch: 39 | Test Loss: 1.06330140431722 | Test F1: 0.35156214237213135\n","Epoch: 40 | Train Loss: 0.9462570548057556\n","Epoch: 40 | Test Loss: 1.0686766902605693 | Test F1: 0.35796260833740234\n","Epoch: 41 | Train Loss: 0.9466243796050549\n","Epoch: 41 | Test Loss: 1.0589052041371663 | Test F1: 0.3445020914077759\n","Epoch: 42 | Train Loss: 0.9398963712155819\n","Epoch: 42 | Test Loss: 1.0433008472124736 | Test F1: 0.36964648962020874\n","Epoch: 43 | Train Loss: 0.9356697648763657\n","Epoch: 43 | Test Loss: 1.045372188091278 | Test F1: 0.3575059175491333\n","Epoch: 44 | Train Loss: 0.932131439447403\n","Epoch: 44 | Test Loss: 1.0270643134911854 | Test F1: 0.3705955147743225\n","Epoch: 45 | Train Loss: 0.9328567311167717\n","Epoch: 45 | Test Loss: 1.0375559628009796 | Test F1: 0.36750879883766174\n","Epoch: 46 | Train Loss: 0.9383795969188213\n","Epoch: 46 | Test Loss: 1.0472469727198284 | Test F1: 0.35506463050842285\n","Epoch: 47 | Train Loss: 0.930273275822401\n","Epoch: 47 | Test Loss: 1.0536215504010518 | Test F1: 0.36334913969039917\n","Epoch: 48 | Train Loss: 0.9276069290935993\n","Epoch: 48 | Test Loss: 1.0545859237511952 | Test F1: 0.3593670129776001\n","Epoch: 49 | Train Loss: 0.9347142539918423\n","Epoch: 49 | Test Loss: 1.055662562449773 | Test F1: 0.35579127073287964\n","Epoch: 50 | Train Loss: 0.9323475882411003\n","Epoch: 50 | Test Loss: 1.043006271123886 | Test F1: 0.36062413454055786\n","Epoch: 51 | Train Loss: 0.9354451149702072\n","Epoch: 51 | Test Loss: 1.0638522903124492 | Test F1: 0.3538937568664551\n","Epoch: 52 | Train Loss: 0.9267689362168312\n","Epoch: 52 | Test Loss: 1.0467376112937927 | Test F1: 0.3614771068096161\n","Epoch: 53 | Train Loss: 0.9309681318700314\n","Epoch: 53 | Test Loss: 1.0431237816810608 | Test F1: 0.36674150824546814\n","Epoch: 54 | Train Loss: 0.9270409159362316\n","Epoch: 54 | Test Loss: 1.0565325419108074 | Test F1: 0.35676488280296326\n","Epoch: 55 | Train Loss: 0.9292545914649963\n","Epoch: 55 | Test Loss: 1.0479759176572163 | Test F1: 0.3586435317993164\n","Epoch: 56 | Train Loss: 0.9224231317639351\n","Epoch: 56 | Test Loss: 1.038667192061742 | Test F1: 0.365527480840683\n","Epoch: 57 | Train Loss: 0.9207032397389412\n","Epoch: 57 | Test Loss: 1.049750546614329 | Test F1: 0.35970795154571533\n","Epoch: 58 | Train Loss: 0.9204601868987083\n","Epoch: 58 | Test Loss: 1.0414289633433025 | Test F1: 0.3582874834537506\n","Epoch: 59 | Train Loss: 0.9230074696242809\n","Epoch: 59 | Test Loss: 1.057066301504771 | Test F1: 0.3552851676940918\n","Epoch: 60 | Train Loss: 0.9236170016229153\n","Epoch: 60 | Test Loss: 1.0676345626513164 | Test F1: 0.3505958914756775\n","Epoch: 61 | Train Loss: 0.9189837723970413\n","Epoch: 61 | Test Loss: 1.0424341261386871 | Test F1: 0.36053401231765747\n","Epoch: 62 | Train Loss: 0.9125256277620792\n","Epoch: 62 | Test Loss: 1.045239766438802 | Test F1: 0.36273419857025146\n","Epoch: 63 | Train Loss: 0.9129397831857204\n","Epoch: 63 | Test Loss: 1.0409810145696003 | Test F1: 0.37010014057159424\n","Epoch: 64 | Train Loss: 0.9151605367660522\n","Epoch: 64 | Test Loss: 1.0500538349151611 | Test F1: 0.35509586334228516\n","Epoch: 65 | Train Loss: 0.9250128082931042\n","Epoch: 65 | Test Loss: 1.0659178495407104 | Test F1: 0.355146586894989\n","Epoch: 66 | Train Loss: 0.9234838373959064\n","Epoch: 66 | Test Loss: 1.0412966410319011 | Test F1: 0.36088746786117554\n","Epoch: 67 | Train Loss: 0.9269362986087799\n","Epoch: 67 | Test Loss: 1.055124839146932 | Test F1: 0.3581634759902954\n","Epoch: 68 | Train Loss: 0.9210499338805676\n","Epoch: 68 | Test Loss: 1.0622742772102356 | Test F1: 0.3583446145057678\n","Epoch: 69 | Train Loss: 0.9189822860062122\n","Epoch: 69 | Test Loss: 1.056763231754303 | Test F1: 0.36301857233047485\n","Epoch: 70 | Train Loss: 0.9212285801768303\n","Epoch: 70 | Test Loss: 1.0548364520072937 | Test F1: 0.3513471186161041\n","Epoch: 71 | Train Loss: 0.9214128814637661\n","Epoch: 71 | Test Loss: 1.0711161295572917 | Test F1: 0.3524194061756134\n","Epoch: 72 | Train Loss: 0.9164766818284988\n","Epoch: 72 | Test Loss: 1.0347222089767456 | Test F1: 0.3649088144302368\n","Epoch: 73 | Train Loss: 0.9156374558806419\n","Epoch: 73 | Test Loss: 1.0384382704893749 | Test F1: 0.3639791011810303\n","Epoch: 74 | Train Loss: 0.9173447489738464\n","Epoch: 74 | Test Loss: 1.0510038534800212 | Test F1: 0.3681737184524536\n","Epoch: 75 | Train Loss: 0.920468270778656\n","Epoch: 75 | Test Loss: 1.0402921636899312 | Test F1: 0.3680032193660736\n","Epoch: 76 | Train Loss: 0.9194339849054813\n","Epoch: 76 | Test Loss: 1.045125385125478 | Test F1: 0.3619581460952759\n","Epoch: 77 | Train Loss: 0.9201715514063835\n","Epoch: 77 | Test Loss: 1.0513070821762085 | Test F1: 0.35615915060043335\n","Epoch: 78 | Train Loss: 0.914043765515089\n","Epoch: 78 | Test Loss: 1.0437407692273457 | Test F1: 0.3669852614402771\n","Epoch: 79 | Train Loss: 0.91781060770154\n","Epoch: 79 | Test Loss: 1.039967546860377 | Test F1: 0.36170363426208496\n","Epoch: 80 | Train Loss: 0.917792372405529\n","Epoch: 80 | Test Loss: 1.0461125175158184 | Test F1: 0.3603370189666748\n","Epoch: 81 | Train Loss: 0.912017609924078\n","Epoch: 81 | Test Loss: 1.0397719740867615 | Test F1: 0.3592691421508789\n","Epoch: 82 | Train Loss: 0.9139868542551994\n","Epoch: 82 | Test Loss: 1.042322079340617 | Test F1: 0.3639693260192871\n","Epoch: 83 | Train Loss: 0.9133590422570705\n","Epoch: 83 | Test Loss: 1.036389817794164 | Test F1: 0.3647710084915161\n","Epoch: 84 | Train Loss: 0.9131584838032722\n","Epoch: 84 | Test Loss: 1.0439891119798024 | Test F1: 0.3617553114891052\n","Epoch: 85 | Train Loss: 0.9120270721614361\n","Epoch: 85 | Test Loss: 1.0346374710400899 | Test F1: 0.36437126994132996\n","Epoch: 86 | Train Loss: 0.9154252521693707\n","Epoch: 86 | Test Loss: 1.054506133000056 | Test F1: 0.35641077160835266\n","Epoch: 87 | Train Loss: 0.9070300459861755\n","Epoch: 87 | Test Loss: 1.0594269235928853 | Test F1: 0.36145803332328796\n","Epoch: 88 | Train Loss: 0.9110191911458969\n","Epoch: 88 | Test Loss: 1.0334741870562236 | Test F1: 0.37129178643226624\n","Epoch: 89 | Train Loss: 0.9181724525988102\n","Epoch: 89 | Test Loss: 1.043664038181305 | Test F1: 0.36837252974510193\n","Epoch: 90 | Train Loss: 0.9170349687337875\n","Epoch: 90 | Test Loss: 1.0587700009346008 | Test F1: 0.35166120529174805\n","Epoch: 91 | Train Loss: 0.9132176600396633\n","Epoch: 91 | Test Loss: 1.0432475010553997 | Test F1: 0.36507952213287354\n","Epoch: 92 | Train Loss: 0.9103624671697617\n","Epoch: 92 | Test Loss: 1.0413773357868195 | Test F1: 0.36016279458999634\n","Epoch: 93 | Train Loss: 0.9132065065205097\n","Epoch: 93 | Test Loss: 1.0411633451779683 | Test F1: 0.35611122846603394\n","Epoch: 94 | Train Loss: 0.9152519106864929\n","Epoch: 94 | Test Loss: 1.0459163784980774 | Test F1: 0.3579897880554199\n","Epoch: 95 | Train Loss: 0.9065671227872372\n","Epoch: 95 | Test Loss: 1.0788585940996807 | Test F1: 0.3491932153701782\n","Epoch: 96 | Train Loss: 0.9106269590556622\n","Epoch: 96 | Test Loss: 1.0406177937984467 | Test F1: 0.3706699013710022\n","Epoch: 97 | Train Loss: 0.9065055102109909\n","Epoch: 97 | Test Loss: 1.0435101489226024 | Test F1: 0.3618272840976715\n","Epoch: 98 | Train Loss: 0.9071424640715122\n","Epoch: 98 | Test Loss: 1.0457773605982463 | Test F1: 0.35853928327560425\n","Epoch: 99 | Train Loss: 0.9101124443113804\n","Epoch: 99 | Test Loss: 1.0500725507736206 | Test F1: 0.35722196102142334\n"]}],"source":["process(model, loss, optimizer, epochs, train_dataloader, test_dataloader)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T14:22:38.822407Z","iopub.status.busy":"2023-11-13T14:22:38.822113Z","iopub.status.idle":"2023-11-13T14:22:42.101760Z","shell.execute_reply":"2023-11-13T14:22:42.100721Z","shell.execute_reply.started":"2023-11-13T14:22:38.822381Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["All Result:\n","Accurcay is:  0.6722560975609756\n","F1 Score is:  0.3572219531880549\n","Confusion Matrix is: \n"," [[317   0   0  45]\n"," [ 64   0   0  13]\n"," [ 24   0   0  10]\n"," [ 59   0   0 124]]\n","\n","Poly Result:\n","Accurcay is:  0.8102409638554217\n","F1 Score is:  0.7764978682025582\n","Confusion Matrix is: \n"," [[199  26]\n"," [ 37  70]]\n","\n","Mono Result:\n","Accurcay is:  0.8075117370892019\n","F1 Score is:  0.7884088871659437\n","Confusion Matrix is: \n"," [[118  19]\n"," [ 22  54]]\n","\n"]}],"source":["with torch.no_grad():\n","    all_preds = []\n","    all_truth = []\n","    mono_preds = []\n","    mono_truth = []\n","    poly_preds = []\n","    poly_truth = []\n","    for image, label, cat in test_dataloader:\n","        image = image.to(DEVICE)\n","        label = label.to(DEVICE)\n","        outputs = model(image)\n","        preds = torch.argmax(outputs, dim=-1)\n","        all_preds += preds.reshape(-1).tolist()\n","        all_truth += label.reshape(-1).tolist()\n","        for idx, c in enumerate(cat):\n","            if c == 0:\n","                mono_preds.append(preds[idx].cpu().item())\n","                mono_truth.append(label[idx].cpu().item())\n","            elif c == 1:\n","                poly_preds.append(preds[idx].cpu().item())\n","                poly_truth.append(label[idx].cpu().item())\n","                \n","acc = accuracy_score(all_truth, all_preds)\n","f1 = f1_score(all_truth, all_preds, average='macro')\n","cm = confusion_matrix(all_truth, all_preds)\n","\n","print('All Result:')\n","print('Accurcay is: ', acc)\n","print('F1 Score is: ', f1)\n","print('Confusion Matrix is: \\n', cm)\n","print()\n","                \n","\n","acc = accuracy_score(poly_truth, poly_preds)\n","f1 = f1_score(poly_truth, poly_preds, average='macro')\n","cm = confusion_matrix(poly_truth, poly_preds)\n","\n","print('Poly Result:')\n","print('Accurcay is: ', acc)\n","print('F1 Score is: ', f1)\n","print('Confusion Matrix is: \\n', cm)\n","print()\n","        \n","        \n","acc = accuracy_score(mono_truth, mono_preds)\n","f1 = f1_score(mono_truth, mono_preds, average='macro')\n","cm = confusion_matrix(mono_truth, mono_preds)\n","\n","print('Mono Result:')\n","print('Accurcay is: ', acc)\n","print('F1 Score is: ', f1)\n","print('Confusion Matrix is: \\n', cm)\n","print()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":3886273,"sourceId":6750013,"sourceType":"datasetVersion"}],"dockerImageVersionId":30580,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}
