{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T23:37:37.134667Z","iopub.status.busy":"2023-11-13T23:37:37.134405Z","iopub.status.idle":"2023-11-13T23:37:44.542073Z","shell.execute_reply":"2023-11-13T23:37:44.541015Z","shell.execute_reply.started":"2023-11-13T23:37:37.134643Z"},"trusted":true},"outputs":[],"source":["import torch\n","\n","# Rely on transformation functions in torch\n","import torchvision.transforms as transforms\n","from torchvision.io import read_image\n","import pandas as pd # for data manipulation\n","import torch.nn as nn # nn: neural network module\n","import os\n","import warnings\n","import numpy as np\n","import seaborn as sns # to visualize data\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n","from torchmetrics.classification import MulticlassF1Score\n","\n","import performancetest as pt\n","\n","# Note: if there is no nvidia gpu, set cuda:0 to cpu\n","warnings.filterwarnings('ignore')\n","DEVICE = 'cuda:0'"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T13:55:09.370542Z","iopub.status.busy":"2023-11-13T13:55:09.370124Z","iopub.status.idle":"2023-11-13T13:55:09.379555Z","shell.execute_reply":"2023-11-13T13:55:09.378544Z","shell.execute_reply.started":"2023-11-13T13:55:09.370516Z"},"trusted":true},"outputs":[],"source":["class CustomImageDataset(Dataset):\n","    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None, filter_fn=None):\n","        \n","        # Read images using pandas\n","        self.img_labels = pd.read_csv(annotations_file, sep=' ', header=None)\n","        if filter_fn is not None:\n","            self.img_labels = self.img_labels[self.img_labels[19] == filter_fn]\n","        \n","        # Save image directory\n","        self.img_dir = img_dir\n","        \n","        # Saving transformation\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    # Return the number of images \n","    def __len__(self):\n","        return len(self.img_labels)\n","    \n","    # Constructs the image path using \n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n","        image = read_image(img_path)\n","        label = self.img_labels.iloc[idx, 2]\n","        if self.transform:\n","            image = self.transform(image)\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","        cat = {'mono': 0, 'poly': 1, np.nan: 3}[self.img_labels.iloc[idx, 19]]\n","        return image, label, cat"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T13:55:09.380866Z","iopub.status.busy":"2023-11-13T13:55:09.380619Z","iopub.status.idle":"2023-11-13T13:55:09.390345Z","shell.execute_reply":"2023-11-13T13:55:09.389611Z","shell.execute_reply.started":"2023-11-13T13:55:09.380842Z"},"trusted":true},"outputs":[],"source":["class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n","        # forced to call the constructor of the parent class to get ResidualBlock\n","        # working as a pytorch module\n","        super(ResidualBlock, self).__init__()\n","        \n","        # Self.conv1 is the main computation\n","        # 3x3 convolution batch normalization and ReLU \n","        self.conv1 = nn.Sequential(\n","                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n","                        nn.BatchNorm2d(out_channels),\n","                        nn.ReLU()) # Using ReLU to fix vanishing gradient problem\n","        \n","        # Also a 3x3 convolution batch but takes in conv1's output to refine conv1's features\n","        self.conv2 = nn.Sequential(\n","                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n","                        nn.BatchNorm2d(out_channels))\n","        \n","        self.downsample = downsample # Optional downsample\n","        self.relu = nn.ReLU()\n","        self.out_channels = out_channels\n","\n","    # Transform input data into output predictions     \n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.conv2(out)\n","        if self.downsample:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","        return out"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T13:55:09.392973Z","iopub.status.busy":"2023-11-13T13:55:09.392650Z","iopub.status.idle":"2023-11-13T13:55:09.407293Z","shell.execute_reply":"2023-11-13T13:55:09.406542Z","shell.execute_reply.started":"2023-11-13T13:55:09.392943Z"},"trusted":true},"outputs":[],"source":["class ResNet(nn.Module):\n","    def __init__(self, block, layers):\n","        super(ResNet, self).__init__()\n","        self.inplanes = 64\n","        self.conv1 = nn.Sequential(\n","                        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3),\n","                        nn.BatchNorm2d(64),\n","                        nn.ReLU())\n","        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n","\n","        # Constructed 4 residual layers\n","        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n","        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n","        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n","        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n","        self.avgpool = nn.AvgPool2d(7, stride=1)\n","        self.fc = nn.Linear(512, 4)\n","        \n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes:\n","            \n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n","                nn.BatchNorm2d(planes),\n","            )\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","    \n","    \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.maxpool(x)\n","        x = self.layer0(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        m_x = torch.softmax(self.fc(x), dim=-1)\n","\n","        return m_x"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T13:55:09.408483Z","iopub.status.busy":"2023-11-13T13:55:09.408236Z","iopub.status.idle":"2023-11-13T13:55:12.502716Z","shell.execute_reply":"2023-11-13T13:55:12.501533Z","shell.execute_reply.started":"2023-11-13T13:55:09.408461Z"},"trusted":true},"outputs":[],"source":["dataset = CustomImageDataset('.\\elpv\\labels.csv', 'elpv/', transform=transforms.Compose([\n","                transforms.ToPILImage(), \n","                transforms.Grayscale(num_output_channels=3),\n","                transforms.Resize((224, 224)),\n","                transforms.ToTensor()\n","            ]),\n","                            target_transform=lambda x: int(x * 3))\n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(len(dataset) * 0.75), int(len(dataset) * 0.25)])\n","train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n","\n","# Create an instance of the resNet model which is moved to DEVICE (idk how to get this working for AMD)\n","model = ResNet(ResidualBlock, [3, 4, 3, 4]).to(DEVICE)\n","\n","# Learning rate (common starting point, too high and the model might fail coverage)\n","lr = 0.001\n","# Set to 100 passes through entire dataset\n","epochs = 100\n","\n","loss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay = 0.001, momentum=0.9) "]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T13:55:12.504800Z","iopub.status.busy":"2023-11-13T13:55:12.504107Z","iopub.status.idle":"2023-11-13T13:55:12.517984Z","shell.execute_reply":"2023-11-13T13:55:12.517021Z","shell.execute_reply.started":"2023-11-13T13:55:12.504771Z"},"trusted":true},"outputs":[],"source":["def process(model, loss_fn, optimizer, epochs, train_dataloader, test_datalodaer):\n","    for epoch in range(epochs):\n","        metric = MulticlassF1Score(num_classes=4, average='macro').to('cuda:0')\n","        steps = 0\n","        acc_loss = 0.0\n","        for image, label, cat in train_dataloader:\n","            image = image.to('cuda:0')\n","            label = label.to('cuda:0')\n","            optimizer.zero_grad()\n","            outputs = model(image)\n","            loss = loss_fn(outputs, label)\n","            loss.backward()\n","            optimizer.step()\n","            steps += 1\n","            acc_loss += loss.item()\n","        print(f'Epoch: {epoch} | Train Loss: {acc_loss / steps}')\n","        \n","        with torch.no_grad():\n","            steps = 0\n","            acc_loss = 0.0\n","            for image, label, cat in test_dataloader:\n","                image = image.to('cuda:0')\n","                label = label.to('cuda:0')\n","                outputs = model(image)\n","                loss = loss_fn(outputs, label)\n","                steps += 1\n","                acc_loss += loss.item()\n","                metric.update(torch.argmax(outputs, dim=-1), label)\n","            print(f'Epoch: {epoch} | Test Loss: {acc_loss / steps} | Test F1: {metric.compute()}')\n","\n","        "]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T13:55:12.521350Z","iopub.status.busy":"2023-11-13T13:55:12.520718Z","iopub.status.idle":"2023-11-13T14:22:38.820975Z","shell.execute_reply":"2023-11-13T14:22:38.820067Z","shell.execute_reply.started":"2023-11-13T13:55:12.521315Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0 | Train Loss: 1.3350647613406181\n","Epoch: 0 | Test Loss: 1.1459824442863464 | Test F1: 0.215562641620636\n","Epoch: 1 | Train Loss: 1.1367039382457733\n","Epoch: 1 | Test Loss: 1.0704142053922017 | Test F1: 0.3185335695743561\n","Epoch: 2 | Train Loss: 1.1034574806690216\n","Epoch: 2 | Test Loss: 1.0465372403462727 | Test F1: 0.3472914695739746\n","Epoch: 3 | Train Loss: 1.092518389225006\n","Epoch: 3 | Test Loss: 1.039229432741801 | Test F1: 0.3523714542388916\n","Epoch: 4 | Train Loss: 1.076904036104679\n"]}],"source":["process(model, loss, optimizer, epochs, train_dataloader, test_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T14:22:38.822407Z","iopub.status.busy":"2023-11-13T14:22:38.822113Z","iopub.status.idle":"2023-11-13T14:22:42.101760Z","shell.execute_reply":"2023-11-13T14:22:42.100721Z","shell.execute_reply.started":"2023-11-13T14:22:38.822381Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'torch' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32md:\\uni\\COMP9517\\comp9517-ass2\\src\\resnet.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/uni/COMP9517/comp9517-ass2/src/resnet.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/uni/COMP9517/comp9517-ass2/src/resnet.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     all_preds \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/uni/COMP9517/comp9517-ass2/src/resnet.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     all_truth \u001b[39m=\u001b[39m []\n","\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"]}],"source":["with torch.no_grad():\n","    all_preds = []\n","    all_truth = []\n","    mono_preds = []\n","    mono_truth = []\n","    poly_preds = []\n","    poly_truth = []\n","    for image, label, cat in test_dataloader:\n","        image = image.to(DEVICE)\n","        label = label.to(DEVICE)\n","        outputs = model(image)\n","        preds = torch.argmax(outputs, dim=-1)\n","        all_preds += preds.reshape(-1).tolist()\n","        all_truth += label.reshape(-1).tolist()\n","        for idx, c in enumerate(cat):\n","            if c == 0:\n","                mono_preds.append(preds[idx].cpu().item())\n","                mono_truth.append(label[idx].cpu().item())\n","            elif c == 1:\n","                poly_preds.append(preds[idx].cpu().item())\n","                poly_truth.append(label[idx].cpu().item())\n","\n","acc = accuracy_score(all_truth, all_preds)\n","f1 = f1_score(all_truth, all_preds, average='macro')\n","cm = confusion_matrix(all_truth, all_preds)\n","\n","print('All Result:')\n","print('Accurcay is: ', acc)\n","print('F1 Score is: ', f1)\n","print('Confusion Matrix is: \\n', cm)\n","print()\n","                \n","\n","acc = accuracy_score(poly_truth, poly_preds)\n","f1 = f1_score(poly_truth, poly_preds, average='macro')\n","cm = confusion_matrix(poly_truth, poly_preds)\n","\n","print('Poly Result:')\n","print('Accurcay is: ', acc)\n","print('F1 Score is: ', f1)\n","print('Confusion Matrix is: \\n', cm)\n","print()\n","        \n","        \n","acc = accuracy_score(mono_truth, mono_preds)\n","f1 = f1_score(mono_truth, mono_preds, average='macro')\n","cm = confusion_matrix(mono_truth, mono_preds)\n","\n","print('Mono Result:')\n","print('Accurcay is: ', acc)\n","print('F1 Score is: ', f1)\n","print('Confusion Matrix is: \\n', cm)\n","print()\n","\n","pt.display_results(mono_truth, poly_truth, mono_preds, poly_preds)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":3886273,"sourceId":6750013,"sourceType":"datasetVersion"}],"dockerImageVersionId":30580,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":