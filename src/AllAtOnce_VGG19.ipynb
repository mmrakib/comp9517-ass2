{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.elpv_reader import load_dataset\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# scikit-learn imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "# tensorflow imports\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.applications import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import Input\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers\n",
    "\n",
    "# from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2624, 300, 300)\n",
      "(2624,)\n",
      "(2624,)\n"
     ]
    }
   ],
   "source": [
    "images, probs, types = load_dataset()\n",
    "print(images.shape)\n",
    "print(probs.shape)\n",
    "print(types.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagesFlipV = np.zeros(images.shape)\n",
    "# probsFlipV = probs.copy()\n",
    "# typesFlipV = types.copy()\n",
    "\n",
    "# for i in range(0, len(images)):\n",
    "#     imagesFlipV[i] = cv2.flip(images[i], 0)\n",
    "\n",
    "# images = np.append(images, imagesFlipV, axis=0)\n",
    "# probs = np.append(probs, probsFlipV)\n",
    "# types = np.append(types, typesFlipV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 132\n",
    "\n",
    "# plt.title(\"original\")\n",
    "# plt.imshow(images[index], cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# norm_img1 = cv2.normalize(images[index], None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "# norm_img1 = (255*norm_img1).astype(np.uint8)\n",
    "# plt.title(\"normalised\")\n",
    "# plt.imshow(norm_img1, cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# kernelLaplacian = np.array([[1, 1, 1],\n",
    "#                            [1, -8, 1],\n",
    "#                            [1, 1, 1]])\n",
    "# edging = cv2.filter2D(src=norm_img1, ddepth=-1, kernel=kernelLaplacian)\n",
    "# plt.title(\"laplacian\")\n",
    "# plt.imshow(edging, cmap='gray', vmin=0, vmax=255)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# t_lower = 25\n",
    "# t_upper = 120\n",
    "# cannyEdges = cv2.Canny(norm_img1, t_lower, t_upper)\n",
    "# plt.title(\"canny\")\n",
    "# plt.imshow(cannyEdges, cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "# retOtsu,thOtsu = cv2.threshold(images[index],0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "# plt.title(\"otsu\")\n",
    "# plt.imshow(thOtsu, cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OTSU IMAGE SEGMENTATION HUEHUEHUE\n",
    "# uncomment below code for otsu segmentation\n",
    "# for i in range(0, len(images)):\n",
    "#     retOtsu,thOtsu = cv2.threshold(images[i],0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "#     images[i] = thOtsu\n",
    "\n",
    "# kernelLaplacian = np.array([[1, 1, 1],\n",
    "#                             [1, -8, 1],\n",
    "#                             [1, 1, 1]])\n",
    "\n",
    "# for i in range(0, len(images)):\n",
    "#     norm_img = cv2.normalize(images[i], None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "#     norm_img = (255*norm_img).astype(np.uint8)\n",
    "#     images[i] = norm_img\n",
    "#     # edging = cv2.filter2D(src=norm_img, ddepth=-1, kernel=kernelLaplacian)\n",
    "#     # images[i] = edging\n",
    "\n",
    "\n",
    "def isPoly(formatted_monopoly_data):\n",
    "    res = np.zeros(len(formatted_monopoly_data))\n",
    "    for i in range(0, len(formatted_monopoly_data)):\n",
    "        res[i] = int(formatted_monopoly_data[i][1])\n",
    "    \n",
    "    return res\n",
    "\n",
    "def getArgMax(probabilities):\n",
    "    res = np.zeros(len(probabilities))\n",
    "    for i in range(0, len(probabilities)):\n",
    "        res[i] = np.argmax(probabilities[i])\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE BIG TRAINING AND TESTING SET\n",
    "images_3 = np.dstack([images] * 3)\n",
    "images_3 = np.reshape(images_3, (-1, 300, 300, 3))\n",
    "\n",
    "probs_formatted = probs\n",
    "probs_label_encoder = LabelEncoder()\n",
    "probs_integer = probs_label_encoder.fit_transform(probs_formatted)\n",
    "probs_formatted = keras.utils.to_categorical(probs_integer)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(images_3, probs_formatted, test_size=0.25, random_state = 420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jaych\\anaconda3\\envs\\tensorflow-directml\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1574 samples, validate on 394 samples\n",
      "Epoch 1/10\n",
      "1574/1574 [==============================] - 14s 9ms/sample - loss: 5.7919 - acc: 0.6182 - val_loss: 1.1096 - val_acc: 0.6472\n",
      "Epoch 2/10\n",
      "1574/1574 [==============================] - 14s 9ms/sample - loss: 0.9652 - acc: 0.6900 - val_loss: 0.8861 - val_acc: 0.6624\n",
      "Epoch 3/10\n",
      "1574/1574 [==============================] - 14s 9ms/sample - loss: 0.6339 - acc: 0.7548 - val_loss: 0.8752 - val_acc: 0.7259\n",
      "Epoch 4/10\n",
      "1574/1574 [==============================] - 14s 9ms/sample - loss: 0.6113 - acc: 0.7706 - val_loss: 0.8119 - val_acc: 0.7284\n",
      "Epoch 5/10\n",
      "1574/1574 [==============================] - 14s 9ms/sample - loss: 0.5620 - acc: 0.7891 - val_loss: 0.8450 - val_acc: 0.7563\n",
      "Epoch 6/10\n",
      "1574/1574 [==============================] - 14s 9ms/sample - loss: 0.5287 - acc: 0.7967 - val_loss: 0.7706 - val_acc: 0.7259\n",
      "Epoch 7/10\n",
      "1574/1574 [==============================] - 14s 9ms/sample - loss: 0.5272 - acc: 0.8062 - val_loss: 0.8029 - val_acc: 0.7437\n",
      "Epoch 8/10\n",
      "1574/1574 [==============================] - 14s 9ms/sample - loss: 0.4623 - acc: 0.8285 - val_loss: 0.9376 - val_acc: 0.7081\n",
      "Epoch 9/10\n",
      "1574/1574 [==============================] - 14s 9ms/sample - loss: 0.4653 - acc: 0.8285 - val_loss: 0.9583 - val_acc: 0.7360\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "# do the same with VGG, but for mono and poly images\n",
    "vgg19_base = keras.applications.VGG19(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
    "vgg19_base.trainable = False\n",
    "\n",
    "vgg19_model = keras.models.Sequential([\n",
    "  vgg19_base,\n",
    "  keras.layers.GlobalAveragePooling2D(),\n",
    "  keras.layers.Flatten(input_shape=vgg19_base.output_shape[1:]),\n",
    "  keras.layers.Dense(4096, activation='relu', kernel_initializer='he_normal'),\n",
    "  keras.layers.Dense(2048, activation='relu', kernel_initializer='he_normal'),\n",
    "  keras.layers.Dense(len(np.unique(probs)), activation='softmax')\n",
    "])\n",
    "\n",
    "vgg19_model.compile(optimizer=keras.optimizers.Adam(learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999, epsilon=1e-08),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 3)\n",
    "\n",
    "history_mono = vgg19_model.fit(x_train, y_train, epochs=10, validation_split = 0.2, callbacks=[es], batch_size=16)\n",
    "\n",
    "PATH = 'models/vgg19_all_model.keras'\n",
    "vgg19_model.save(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.79      0.80       396\n",
      "         1.0       0.43      0.30      0.35       101\n",
      "         2.0       0.00      0.00      0.00         1\n",
      "         3.0       0.71      0.82      0.76       158\n",
      "\n",
      "    accuracy                           0.72       656\n",
      "   macro avg       0.49      0.47      0.48       656\n",
      "weighted avg       0.74      0.72      0.72       656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# score = vgg19_model.evaluate(x_test, y_test)\n",
    "result = vgg19_model.predict(x_test)\n",
    "# print(dict(zip(vgg19_model.metrics_names, score)))\n",
    "# print(vgg19_model.metrics_names)\n",
    "\n",
    "def getArgMax(probabilities):\n",
    "    res = np.zeros(len(probabilities))\n",
    "    for i in range(0, len(probabilities)):\n",
    "        res[i] = np.argmax(probabilities[i])\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "predicted_int = getArgMax(result)\n",
    "y_test_int = getArgMax(y_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(predicted_int, y_test_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
