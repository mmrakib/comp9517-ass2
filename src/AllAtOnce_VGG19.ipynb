{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.elpv_reader import load_dataset\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# scikit-learn imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "# tensorflow imports\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.applications import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import Input\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers\n",
    "\n",
    "# from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2624, 300, 300)\n",
      "(2624,)\n",
      "(2624,)\n"
     ]
    }
   ],
   "source": [
    "images, probs, types = load_dataset()\n",
    "print(images.shape)\n",
    "print(probs.shape)\n",
    "print(types.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OTSU IMAGE SEGMENTATION HUEHUEHUE\n",
    "# uncomment below code for otsu segmentation\n",
    "# for i in range(0, len(images)):\n",
    "#     retOtsu,thOtsu = cv2.threshold(images[i],0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "#     images[i] = thOtsu\n",
    "\n",
    "# kernelLaplacian = np.array([[1, 1, 1],\n",
    "#                             [1, -8, 1],\n",
    "#                             [1, 1, 1]])\n",
    "\n",
    "# for i in range(0, len(images)):\n",
    "#     norm_img = cv2.normalize(images[i], None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "#     norm_img = (255*norm_img).astype(np.uint8)\n",
    "#     images[i] = norm_img\n",
    "#     # edging = cv2.filter2D(src=norm_img, ddepth=-1, kernel=kernelLaplacian)\n",
    "#     # images[i] = edging\n",
    "\n",
    "\n",
    "def isPoly(formatted_monopoly_data):\n",
    "    res = np.zeros(len(formatted_monopoly_data))\n",
    "    for i in range(0, len(formatted_monopoly_data)):\n",
    "        res[i] = int(formatted_monopoly_data[i][1])\n",
    "    \n",
    "    return res\n",
    "\n",
    "def getArgMax(probabilities):\n",
    "    res = np.zeros(len(probabilities))\n",
    "    for i in range(0, len(probabilities)):\n",
    "        res[i] = np.argmax(probabilities[i])\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE BIG TRAINING AND TESTING SET\n",
    "images_3 = np.dstack([images] * 3)\n",
    "images_3 = np.reshape(images_3, (-1, 300, 300, 3))\n",
    "\n",
    "probs_formatted = probs\n",
    "probs_label_encoder = LabelEncoder()\n",
    "probs_integer = probs_label_encoder.fit_transform(probs_formatted)\n",
    "\n",
    "probs_formatted = keras.utils.to_categorical(probs_integer)\n",
    "\n",
    "types_formatted = types\n",
    "types_label_encoder = LabelEncoder()\n",
    "types_formatted = types_label_encoder.fit_transform(types_formatted)\n",
    "types_formatted = keras.utils.to_categorical(types_formatted)\n",
    "\n",
    "images_3_mono = images_3[types == \"mono\"]\n",
    "images_3_poly = images_3[types == \"poly\"]\n",
    "probs_formatted_mono = probs_formatted[types == \"mono\"]\n",
    "probs_formatted_poly = probs_formatted[types == \"poly\"]\n",
    "\n",
    "# Format \"types_formatted\" into \"types_formatted | probs\" for splitting data\n",
    "types_probs_formatted = np.zeros((len(types_formatted), len(types_formatted[0]) + len(probs_formatted[0])))\n",
    "for i in range (0, len(types_probs_formatted)):\n",
    "    # types_probs_formatted[i] = np.concatenate(types_formatted[i], probs_formatted[i])\n",
    "    types_probs_formatted[i, 0:len(types_formatted[0]):1] = types_formatted[i]\n",
    "    types_probs_formatted[i, len(types_formatted[0]):len(types_probs_formatted[0]):1] = probs_formatted[i]\n",
    "\n",
    "\n",
    "# training and testing data for types and final classifiers:\n",
    "#   split types into test and train\n",
    "#   x_train, test\n",
    "#   y_mp_train, test\n",
    "#   y_probs_train, test\n",
    "x_train, x_test, y_combo_train, y_combo_test = train_test_split(images_3, types_probs_formatted, test_size=0.25, random_state=690)\n",
    "\n",
    "y_mp_train = y_combo_train[:, 0:2]\n",
    "y_train = y_combo_train[:, 2:6]\n",
    "\n",
    "y_mp_test = y_combo_test[:, 0:2]\n",
    "y_test = y_combo_test[:, 2:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1574 samples, validate on 394 samples\n",
      "Epoch 1/10\n",
      "1574/1574 [==============================] - 14s 9ms/sample - loss: 6.5184 - acc: 0.6042 - val_loss: 1.1947 - val_acc: 0.5736\n",
      "Epoch 2/10\n",
      "1574/1574 [==============================] - 13s 9ms/sample - loss: 0.8944 - acc: 0.7084 - val_loss: 0.8146 - val_acc: 0.7360\n",
      "Epoch 3/10\n",
      "1574/1574 [==============================] - 14s 9ms/sample - loss: 0.7118 - acc: 0.7503 - val_loss: 0.7605 - val_acc: 0.7437\n",
      "Epoch 4/10\n",
      "1574/1574 [==============================] - 14s 9ms/sample - loss: 0.6048 - acc: 0.7795 - val_loss: 0.7480 - val_acc: 0.7386\n",
      "Epoch 5/10\n",
      "1574/1574 [==============================] - 14s 9ms/sample - loss: 0.5593 - acc: 0.7992 - val_loss: 0.8055 - val_acc: 0.7157\n",
      "Epoch 6/10\n",
      "1574/1574 [==============================] - 14s 9ms/sample - loss: 0.5371 - acc: 0.8088 - val_loss: 0.8844 - val_acc: 0.7284\n",
      "Epoch 7/10\n",
      "1574/1574 [==============================] - 14s 9ms/sample - loss: 0.5236 - acc: 0.8056 - val_loss: 1.0855 - val_acc: 0.6371\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "# do the same with VGG, but for mono and poly images\n",
    "vgg19_base = keras.applications.VGG19(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
    "vgg19_base.trainable = False\n",
    "\n",
    "vgg19_model = keras.models.Sequential([\n",
    "  vgg19_base,\n",
    "  keras.layers.GlobalAveragePooling2D(),\n",
    "  keras.layers.Flatten(input_shape=vgg19_base.output_shape[1:]),\n",
    "  keras.layers.Dense(4096, activation='relu', kernel_initializer='he_normal'),\n",
    "  keras.layers.Dense(2048, activation='relu', kernel_initializer='he_normal'),\n",
    "  keras.layers.Dense(len(np.unique(probs)), activation='softmax')\n",
    "])\n",
    "\n",
    "vgg19_model.compile(optimizer=keras.optimizers.Adam(learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999, epsilon=1e-08),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 3)\n",
    "\n",
    "history_mono = vgg19_model.fit(x_train, y_train, epochs=10, validation_split = 0.2, callbacks=[es], batch_size=16)\n",
    "\n",
    "# PATH = 'models/vgg19_all_model.keras'\n",
    "# vgg19_model.save(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.82       402\n",
      "         1.0       0.49      0.38      0.43        90\n",
      "         2.0       0.04      1.00      0.07         1\n",
      "         3.0       0.73      0.82      0.77       163\n",
      "\n",
      "    accuracy                           0.74       656\n",
      "   macro avg       0.53      0.75      0.52       656\n",
      "weighted avg       0.77      0.74      0.75       656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# score = vgg19_model.evaluate(x_test, y_test)\n",
    "result = vgg19_model.predict(x_test)\n",
    "# print(dict(zip(vgg19_model.metrics_names, score)))\n",
    "# print(vgg19_model.metrics_names)\n",
    "\n",
    "def getArgMax(probabilities):\n",
    "    res = np.zeros(len(probabilities))\n",
    "    for i in range(0, len(probabilities)):\n",
    "        res[i] = np.argmax(probabilities[i])\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "predicted_int = getArgMax(result)\n",
    "y_test_int = getArgMax(y_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(predicted_int, y_test_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaych\\anaconda3\\envs\\tensorflow-directml\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\Users\\jaych\\anaconda3\\envs\\tensorflow-directml\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\Users\\jaych\\anaconda3\\envs\\tensorflow-directml\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  \"\"\"\n",
      "c:\\Users\\jaych\\anaconda3\\envs\\tensorflow-directml\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import performancetest as pt\n",
    "\n",
    "y_true_m = y_test_int[isPoly(y_mp_test) == \"mono\"]\n",
    "y_true_p = y_test_int[isPoly(y_mp_test) == \"poly\"]\n",
    "y_predict_m = predicted_int[isPoly(y_mp_test) == \"mono\"]\n",
    "y_predict_p = predicted_int[isPoly(y_mp_test) == \"poly\"]\n",
    "\n",
    "pt.display_results(y_true_m, y_true_p, y_predict_m, y_predict_p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
